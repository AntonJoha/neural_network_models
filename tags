!_TAG_EXTRA_DESCRIPTION	anonymous	/Include tags for non-named objects like lambda/
!_TAG_EXTRA_DESCRIPTION	fileScope	/Include tags of file scope/
!_TAG_EXTRA_DESCRIPTION	pseudo	/Include pseudo tags/
!_TAG_EXTRA_DESCRIPTION	subparser	/Include tags generated by subparsers/
!_TAG_FIELD_DESCRIPTION	epoch	/the last modified time of the input file (only for F\/file kind tag)/
!_TAG_FIELD_DESCRIPTION	file	/File-restricted scoping/
!_TAG_FIELD_DESCRIPTION	input	/input file/
!_TAG_FIELD_DESCRIPTION	name	/tag name/
!_TAG_FIELD_DESCRIPTION	pattern	/pattern/
!_TAG_FIELD_DESCRIPTION	typeref	/Type and name of a variable or typedef/
!_TAG_FIELD_DESCRIPTION!Python	nameref	/the original name for the tag/
!_TAG_FILE_FORMAT	2	/extended format; --format=1 will not append ;" to lines/
!_TAG_FILE_SORTED	1	/0=unsorted, 1=sorted, 2=foldcase/
!_TAG_KIND_DESCRIPTION!Python	I,namespace	/name referring a module defined in other file/
!_TAG_KIND_DESCRIPTION!Python	Y,unknown	/name referring a class\/variable\/function\/module defined in other module/
!_TAG_KIND_DESCRIPTION!Python	c,class	/classes/
!_TAG_KIND_DESCRIPTION!Python	f,function	/functions/
!_TAG_KIND_DESCRIPTION!Python	i,module	/modules/
!_TAG_KIND_DESCRIPTION!Python	m,member	/class members/
!_TAG_KIND_DESCRIPTION!Python	v,variable	/variables/
!_TAG_OUTPUT_EXCMD	mixed	/number, pattern, mixed, or combineV2/
!_TAG_OUTPUT_FILESEP	slash	/slash or backslash/
!_TAG_OUTPUT_MODE	u-ctags	/u-ctags or e-ctags/
!_TAG_OUTPUT_VERSION	0.0	/current.age/
!_TAG_PARSER_VERSION!Python	0.0	/current.age/
!_TAG_PATTERN_LENGTH_LIMIT	96	/0 for no limit/
!_TAG_PROC_CWD	/home/kentagent/Documents/code/neural_network_models/	//
!_TAG_PROGRAM_AUTHOR	Universal Ctags Team	//
!_TAG_PROGRAM_NAME	Universal Ctags	/Derived from Exuberant Ctags/
!_TAG_PROGRAM_URL	https://ctags.io/	/official site/
!_TAG_PROGRAM_VERSION	6.1.0	//
!_TAG_ROLE_DESCRIPTION!Python!module	imported	/imported modules/
!_TAG_ROLE_DESCRIPTION!Python!module	indirectlyImported	/module imported in alternative name/
!_TAG_ROLE_DESCRIPTION!Python!module	namespace	/namespace from where classes\/variables\/functions are imported/
!_TAG_ROLE_DESCRIPTION!Python!unknown	imported	/imported from the other module/
!_TAG_ROLE_DESCRIPTION!Python!unknown	indirectlyImported	/classes\/variables\/functions\/modules imported in alternative name/
Actor	RL/ddpg_agent.py	/^class Actor(nn.Module):$/;"	c
DDPG	RL/ddpg_agent.py	/^class DDPG:$/;"	c
DQNAgent	RL/dqn_agent.py	/^class DQNAgent:$/;"	c
QNetwork	RL/ddpg_agent.py	/^class QNetwork(nn.Module):$/;"	c
QNetwork	RL/dqn_agent.py	/^class QNetwork(nn.Module):$/;"	c
ReplayBuffer	RL/ReplayBuffer.py	/^class ReplayBuffer:$/;"	c
_	RL/ddpg_agent.py	/^    state,_ = env.reset()$/;"	v
_	RL/dqn_agent.py	/^    state, _ = env.reset()$/;"	v
__init__	RL/ReplayBuffer.py	/^    def __init__(self, capacity):$/;"	m	class:ReplayBuffer
__init__	RL/ddpg_agent.py	/^    def __init__(self, config=None):$/;"	m	class:Actor
__init__	RL/ddpg_agent.py	/^    def __init__(self, config=None):$/;"	m	class:QNetwork
__init__	RL/ddpg_agent.py	/^    def __init__(self,config=None):$/;"	m	class:DDPG
__init__	RL/dqn_agent.py	/^    def __init__(self, config=None):$/;"	m	class:QNetwork
__init__	RL/dqn_agent.py	/^    def __init__(self, config=None, optimizer=optim.SGD, loss=nn.MSELoss()):$/;"	m	class:DQNAgent
a	RL/dqn_agent.py	/^    a = DQNAgent(conf)$/;"	v
action	RL/ddpg_agent.py	/^    action = ddpg.select_action(state,10000.1)$/;"	v
action	RL/dqn_agent.py	/^    action = a.select_action(state)$/;"	v
actor	RL/ddpg_agent.py	/^    actor = Actor(conf)$/;"	v
adam_wrapper	RL/ddpg_agent.py	/^    def adam_wrapper(parameters, lr, config):$/;"	f
adam_wrapper	RL/dqn_agent.py	/^    def adam_wrapper(parameters, lr, config):$/;"	f
add	RL/ReplayBuffer.py	/^    def add(self, experience):$/;"	m	class:ReplayBuffer
buffer	RL/ddpg_agent.py	/^    buffer = ReplayBuffer(1000)$/;"	v
buffer	RL/dqn_agent.py	/^    buffer = ReplayBuffer(1000)$/;"	v
buffer_size	RL/ReplayBuffer.py	/^    def buffer_size(self):$/;"	m	class:ReplayBuffer
conf	RL/ddpg_agent.py	/^    conf = { "input": 2,$/;"	v
conf	RL/dqn_agent.py	/^    conf = { "input": 6,$/;"	v
critic	RL/ddpg_agent.py	/^    critic = QNetwork(conf)$/;"	v
ddpg	RL/ddpg_agent.py	/^    ddpg = DDPG(conf)$/;"	v
device	RL/ddpg_agent.py	/^device = torch.device("cuda" if torch.cuda.is_available() else "cpu")$/;"	v
device	RL/dqn_agent.py	/^device = torch.device("cuda" if torch.cuda.is_available() else "cpu")$/;"	v
env	RL/ddpg_agent.py	/^    env = gym.make("MountainCarContinuous-v0")$/;"	v
env	RL/dqn_agent.py	/^    env = gym.make("Acrobot-v1")$/;"	v
evaluate_mode	RL/dqn_agent.py	/^    def evaluate_mode(self):$/;"	m	class:DQNAgent
forward	RL/ddpg_agent.py	/^    def forward(self, data):$/;"	m	class:Actor
forward	RL/ddpg_agent.py	/^    def forward(self, data):$/;"	m	class:QNetwork
forward	RL/dqn_agent.py	/^    def forward(self, data):$/;"	m	class:QNetwork
get_learning_rate	RL/dqn_agent.py	/^    def get_learning_rate(self):$/;"	m	class:DQNAgent
get_network_weights	RL/dqn_agent.py	/^    def get_network_weights(self):$/;"	m	class:DQNAgent
get_noise_rate	RL/ddpg_agent.py	/^    def get_noise_rate(self):$/;"	m	class:DDPG
get_noise_rate	RL/dqn_agent.py	/^    def get_noise_rate(self):$/;"	m	class:DQNAgent
gym	RL/ddpg_agent.py	/^    import gymnasium as gym$/;"	I	nameref:module:gymnasium
gym	RL/dqn_agent.py	/^    import gymnasium as gym$/;"	I	nameref:module:gymnasium
info	RL/ddpg_agent.py	/^    next_state, reward, terminated, truncated, info = env.step(action.detach().numpy())$/;"	v
info	RL/dqn_agent.py	/^    next_state, reward, terminated ,truncated, info = env.step(action)$/;"	v
make_layers	RL/ddpg_agent.py	/^    def make_layers(self):$/;"	m	class:Actor
make_layers	RL/ddpg_agent.py	/^    def make_layers(self):$/;"	m	class:QNetwork
make_layers	RL/dqn_agent.py	/^    def make_layers(self):$/;"	m	class:QNetwork
next_state	RL/ddpg_agent.py	/^    next_state, reward, terminated, truncated, info = env.step(action.detach().numpy())$/;"	v
next_state	RL/dqn_agent.py	/^    next_state, reward, terminated ,truncated, info = env.step(action)$/;"	v
nn	RL/ddpg_agent.py	/^import torch.nn as nn$/;"	I	nameref:module:torch.nn
nn	RL/dqn_agent.py	/^import torch.nn as nn$/;"	I	nameref:module:torch.nn
np	RL/ReplayBuffer.py	/^import numpy as np$/;"	I	nameref:module:numpy
np	RL/ddpg_agent.py	/^import numpy as np$/;"	I	nameref:module:numpy
np	RL/dqn_agent.py	/^import numpy as np$/;"	I	nameref:module:numpy
optim	RL/ddpg_agent.py	/^import torch.optim as optim$/;"	I	nameref:module:torch.optim
optim	RL/dqn_agent.py	/^import torch.optim as optim$/;"	I	nameref:module:torch.optim
replay	RL/dqn_agent.py	/^    def replay(self,replay_buffer,batch_size=128,target_network=True):$/;"	m	class:DQNAgent
reward	RL/ddpg_agent.py	/^    next_state, reward, terminated, truncated, info = env.step(action.detach().numpy())$/;"	v
reward	RL/dqn_agent.py	/^    next_state, reward, terminated ,truncated, info = env.step(action)$/;"	v
sample	RL/ReplayBuffer.py	/^    def sample(self, batch_size):$/;"	m	class:ReplayBuffer
select_action	RL/ddpg_agent.py	/^    def select_action(self, state, std=0):$/;"	m	class:DDPG
select_action	RL/dqn_agent.py	/^    def select_action(self, state, exploration_prob=0):$/;"	m	class:DQNAgent
set_learning_rate	RL/dqn_agent.py	/^    def set_learning_rate(self,lr):$/;"	m	class:DQNAgent
set_network_weights	RL/dqn_agent.py	/^    def set_network_weights(self,weights):$/;"	m	class:DQNAgent
set_noise_rate	RL/dqn_agent.py	/^    def set_noise_rate(self, noise):$/;"	m	class:DQNAgent
state	RL/ddpg_agent.py	/^    state,_ = env.reset()$/;"	v
state	RL/dqn_agent.py	/^    state, _ = env.reset()$/;"	v
terminated	RL/ddpg_agent.py	/^    next_state, reward, terminated, truncated, info = env.step(action.detach().numpy())$/;"	v
terminated	RL/dqn_agent.py	/^    next_state, reward, terminated ,truncated, info = env.step(action)$/;"	v
train_mode	RL/dqn_agent.py	/^    def train_mode(self):$/;"	m	class:DQNAgent
truncated	RL/ddpg_agent.py	/^    next_state, reward, terminated, truncated, info = env.step(action.detach().numpy())$/;"	v
truncated	RL/dqn_agent.py	/^    next_state, reward, terminated ,truncated, info = env.step(action)$/;"	v
update_lr	RL/ddpg_agent.py	/^    def update_lr(self, count):$/;"	m	class:DDPG
update_target_q_network	RL/dqn_agent.py	/^    def update_target_q_network(self):$/;"	m	class:DQNAgent
